{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9da32d6",
   "metadata": {
    "id": "c9da32d6"
   },
   "source": [
    "# NLP Using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8326ba88",
   "metadata": {
    "id": "8326ba88"
   },
   "source": [
    "## Objective:\n",
    "- The objective from this project is to create a <b>Spam filter using NaiveBayes classifier</b>.\n",
    "- It is required to obtain <b>f1_scored > 0.9</b>.\n",
    "- We'll use a dataset from UCI Repository. SMS Spam Detection: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "- Data is also provided for you in the assignment (you do not have to download it)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6971f788",
   "metadata": {
    "id": "6971f788"
   },
   "source": [
    "## To perform this task follow the following guiding steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bc851",
   "metadata": {
    "id": "e31bc851"
   },
   "source": [
    "### Create a spark session and import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcf86e46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcf86e46",
    "outputId": "85f5b329-1cd1-4727-e519-d7dbb51a1d3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.3 MB 35 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9.2\n",
      "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 59.6 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=b3b17ca0776427c4eba6dfc2ccbad5fe3d0664a727c117578f9a485f56429d33\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
     ]
    }
   ],
   "source": [
    "# Install java\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "# Install spark (change the version number if needed)\n",
    "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
    "\n",
    "# Unzip the spark file to the current folder\n",
    "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
    "\n",
    "# Set your spark folder to your system path environment. \n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
    "\n",
    "# Install findspark using pip\n",
    "!pip install -q findspark\n",
    "\n",
    "# Spark for Python\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "CuV1NsTGejae",
   "metadata": {
    "id": "CuV1NsTGejae"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "EtzgyoDDe5Ur",
   "metadata": {
    "id": "EtzgyoDDe5Ur"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4wHMxPANe-r8",
   "metadata": {
    "id": "4wHMxPANe-r8"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sp = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7df9e",
   "metadata": {
    "id": "90c7df9e"
   },
   "source": [
    "### Read the readme file to learn more about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00718f",
   "metadata": {
    "id": "2d00718f"
   },
   "source": [
    "### Read the data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "29914cf1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29914cf1",
    "outputId": "98baa995-d134-45b3-94b8-b09db9be33c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|ham\tGo until juro...|\n",
      "|ham\tOk lar... Jok...|\n",
      "|spam\tFree entry i...|\n",
      "|ham\tU dun say so ...|\n",
      "|ham\tNah I don't t...|\n",
      "|spam\tFreeMsg Hey ...|\n",
      "|ham\tEven my broth...|\n",
      "|ham\tAs per your r...|\n",
      "|spam\tWINNER!! As ...|\n",
      "|spam\tHad your mob...|\n",
      "|ham\tI'm gonna be ...|\n",
      "|spam\tSIX chances ...|\n",
      "|spam\tURGENT! You ...|\n",
      "|ham\tI've been sea...|\n",
      "|ham\tI HAVE A DATE...|\n",
      "|spam\tXXXMobileMov...|\n",
      "|ham\tOh k...i'm wa...|\n",
      "|ham\tEh u remember...|\n",
      "|ham\tFine if that...|\n",
      "|spam\tEngland v Ma...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.text(\"/content/SMSSpamCollection\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182cd7f6",
   "metadata": {
    "id": "182cd7f6"
   },
   "source": [
    "### Print the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b52706b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b52706b9",
    "outputId": "3e79b8fd-ae11-469a-a45c-b22a3b48d8a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90cce7",
   "metadata": {
    "id": "2b90cce7"
   },
   "source": [
    "### Rename the first column to 'class' and second column to 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "gTGB7PPEje_5",
   "metadata": {
    "id": "gTGB7PPEje_5"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f1a88df6",
   "metadata": {
    "id": "f1a88df6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('class', f.split(df['value'], '\t')[0])\n",
    "df = df.withColumn('text', f.split(df['value'], '\t')[1])\n",
    "df = df.drop(\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "mjtBlqUcl40A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjtBlqUcl40A",
    "outputId": "76ea5748-9db5-484e-9e85-e3f4445e76ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|                text|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "|  ham|U dun say so earl...|\n",
      "|  ham|Nah I don't think...|\n",
      "| spam|FreeMsg Hey there...|\n",
      "|  ham|Even my brother i...|\n",
      "|  ham|As per your reque...|\n",
      "| spam|WINNER!! As a val...|\n",
      "| spam|Had your mobile 1...|\n",
      "|  ham|I'm gonna be home...|\n",
      "| spam|SIX chances to wi...|\n",
      "| spam|URGENT! You have ...|\n",
      "|  ham|I've been searchi...|\n",
      "|  ham|I HAVE A DATE ON ...|\n",
      "| spam|XXXMobileMovieClu...|\n",
      "|  ham|Oh k...i'm watchi...|\n",
      "|  ham|Eh u remember how...|\n",
      "|  ham|Fine if thats th...|\n",
      "| spam|England v Macedon...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e798d0",
   "metadata": {
    "id": "a3e798d0"
   },
   "source": [
    "### Show the first 10 rows from the dataframe\n",
    "- Show once with truncate=True and once with truncate=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "362dcb99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "362dcb99",
    "outputId": "e673e2b2-3708-4a1b-9580-b0d0b7f1beb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|                text|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "|  ham|U dun say so earl...|\n",
      "|  ham|Nah I don't think...|\n",
      "| spam|FreeMsg Hey there...|\n",
      "|  ham|Even my brother i...|\n",
      "|  ham|As per your reque...|\n",
      "| spam|WINNER!! As a val...|\n",
      "| spam|Had your mobile 1...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "41609e6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41609e6b",
    "outputId": "90acf070-1bc3-459f-d7cd-eae6421757de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|class|text                                                                                                                                                            |\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                                 |\n",
      "|ham  |Ok lar... Joking wif u oni...                                                                                                                                   |\n",
      "|spam |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's     |\n",
      "|ham  |U dun say so early hor... U c already then say...                                                                                                               |\n",
      "|ham  |Nah I don't think he goes to usf, he lives around here though                                                                                                   |\n",
      "|spam |FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv             |\n",
      "|ham  |Even my brother is not like to speak with me. They treat me like aids patent.                                                                                   |\n",
      "|ham  |As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune|\n",
      "|spam |WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.   |\n",
      "|spam |Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030      |\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe744a9",
   "metadata": {
    "id": "2fe744a9"
   },
   "source": [
    "## Clean and Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d693167",
   "metadata": {
    "id": "4d693167"
   },
   "source": [
    "### Create a new feature column contains the length of the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5424a0cb",
   "metadata": {
    "id": "5424a0cb"
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('length', f.length('text') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea2de6",
   "metadata": {
    "id": "78ea2de6"
   },
   "source": [
    "### Show the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "04c67c53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04c67c53",
    "outputId": "8208e301-02b0-4d6e-89a0-786821098e6c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|                text|length|\n",
      "+-----+--------------------+------+\n",
      "|  ham|Go until jurong p...|   111|\n",
      "|  ham|Ok lar... Joking ...|    29|\n",
      "| spam|Free entry in 2 a...|   155|\n",
      "|  ham|U dun say so earl...|    49|\n",
      "|  ham|Nah I don't think...|    61|\n",
      "| spam|FreeMsg Hey there...|   147|\n",
      "|  ham|Even my brother i...|    77|\n",
      "|  ham|As per your reque...|   160|\n",
      "| spam|WINNER!! As a val...|   157|\n",
      "| spam|Had your mobile 1...|   154|\n",
      "|  ham|I'm gonna be home...|   109|\n",
      "| spam|SIX chances to wi...|   136|\n",
      "| spam|URGENT! You have ...|   155|\n",
      "|  ham|I've been searchi...|   196|\n",
      "|  ham|I HAVE A DATE ON ...|    35|\n",
      "| spam|XXXMobileMovieClu...|   149|\n",
      "|  ham|Oh k...i'm watchi...|    26|\n",
      "|  ham|Eh u remember how...|    81|\n",
      "|  ham|Fine if thats th...|    56|\n",
      "| spam|England v Macedon...|   155|\n",
      "+-----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e37a6",
   "metadata": {
    "id": "692e37a6"
   },
   "source": [
    "### Get the average text length for each class (give alias name to the average length column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5c32727d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c32727d",
    "outputId": "8581f473-9304-4354-b408-b8758aa25eec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|class|      avg(length)|\n",
      "+-----+-----------------+\n",
      "|  ham|71.47192873420344|\n",
      "| spam|138.6760374832664|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"class\").avg(\"length\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e101af",
   "metadata": {
    "id": "d5e101af"
   },
   "source": [
    "## Feature Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838ad9dd",
   "metadata": {
    "id": "838ad9dd"
   },
   "source": [
    "### In this part you transform you raw text in to tf_idf model :\n",
    "- For more information about TF-IDF check the following link: <b>(Not needed for the test)</b>\n",
    "https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225067d5",
   "metadata": {
    "id": "225067d5"
   },
   "source": [
    "### Perform the following steps to obtain TF-IDF:\n",
    "1. Import the required transformers/estimators for the subsequent steps.\n",
    "2. Create a <b>Tokenizer</b> from the text column.\n",
    "3. Create a <b>StopWordsRemover</b> to remove the <b>stop words</b> from the column obtained from the <b>Tokenizer</b>.\n",
    "4. Create a <b>CountVectorizer</b> after removing the <b>stop words</b>.\n",
    "5. Create the <b>TF-IDF</b> from the <b>CountVectorizer</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6a4eebf8",
   "metadata": {
    "id": "6a4eebf8"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer,  StopWordsRemover, CountVectorizer, IDF, StringIndexer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "rsbU74DM4qmr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rsbU74DM4qmr",
    "outputId": "155c3dab-a929-4f88-bed9-c9027a84e526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|  0.0|Go until jurong p...|\n",
      "|  0.0|Ok lar... Joking ...|\n",
      "|  1.0|Free entry in 2 a...|\n",
      "|  0.0|U dun say so earl...|\n",
      "|  0.0|Nah I don't think...|\n",
      "|  1.0|FreeMsg Hey there...|\n",
      "|  0.0|Even my brother i...|\n",
      "|  0.0|As per your reque...|\n",
      "|  1.0|WINNER!! As a val...|\n",
      "|  1.0|Had your mobile 1...|\n",
      "|  0.0|I'm gonna be home...|\n",
      "|  1.0|SIX chances to wi...|\n",
      "|  1.0|URGENT! You have ...|\n",
      "|  0.0|I've been searchi...|\n",
      "|  0.0|I HAVE A DATE ON ...|\n",
      "|  1.0|XXXMobileMovieClu...|\n",
      "|  0.0|Oh k...i'm watchi...|\n",
      "|  0.0|Eh u remember how...|\n",
      "|  0.0|Fine if thats th...|\n",
      "|  1.0|England v Macedon...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\").fit(df)\n",
    "df_ind = indexer.transform(df).select(\"label\",\"text\")\n",
    "df_ind.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b82756db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b82756db",
    "outputId": "771898e8-a802-4b8a-89e1-671480721e61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|         words_token|\n",
      "+-----+--------------------+\n",
      "|  0.0|[go, until, juron...|\n",
      "|  0.0|[ok, lar..., joki...|\n",
      "|  1.0|[free, entry, in,...|\n",
      "|  0.0|[u, dun, say, so,...|\n",
      "|  0.0|[nah, i, don't, t...|\n",
      "|  1.0|[freemsg, hey, th...|\n",
      "|  0.0|[even, my, brothe...|\n",
      "|  0.0|[as, per, your, r...|\n",
      "|  1.0|[winner!!, as, a,...|\n",
      "|  1.0|[had, your, mobil...|\n",
      "|  0.0|[i'm, gonna, be, ...|\n",
      "|  1.0|[six, chances, to...|\n",
      "|  1.0|[urgent!, you, ha...|\n",
      "|  0.0|[i've, been, sear...|\n",
      "|  0.0|[i, have, a, date...|\n",
      "|  1.0|[xxxmobilemoviecl...|\n",
      "|  0.0|[oh, k...i'm, wat...|\n",
      "|  0.0|[eh, u, remember,...|\n",
      "|  0.0|[fine, if, thats...|\n",
      "|  1.0|[england, v, mace...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol='text', outputCol='words_token')\n",
    "df_words_token = tokenizer.transform(df_ind).select('label', 'words_token')\n",
    "df_words_token.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ausl5nKZr_Bm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ausl5nKZr_Bm",
    "outputId": "370d1e9c-df76-4ff7-9709-bc7cc861fef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|         words_clean|\n",
      "+-----+--------------------+\n",
      "|  0.0|[go, jurong, poin...|\n",
      "|  0.0|[ok, lar..., joki...|\n",
      "|  1.0|[free, entry, 2, ...|\n",
      "|  0.0|[u, dun, say, ear...|\n",
      "|  0.0|[nah, think, goes...|\n",
      "|  1.0|[freemsg, hey, da...|\n",
      "|  0.0|[even, brother, l...|\n",
      "|  0.0|[per, request, 'm...|\n",
      "|  1.0|[winner!!, valued...|\n",
      "|  1.0|[mobile, 11, mont...|\n",
      "|  0.0|[gonna, home, soo...|\n",
      "|  1.0|[six, chances, wi...|\n",
      "|  1.0|[urgent!, won, 1,...|\n",
      "|  0.0|[searching, right...|\n",
      "|  0.0|[date, sunday, wi...|\n",
      "|  1.0|[xxxmobilemoviecl...|\n",
      "|  0.0|[oh, k...i'm, wat...|\n",
      "|  0.0|[eh, u, remember,...|\n",
      "|  0.0|[fine, thats, wa...|\n",
      "|  1.0|[england, v, mace...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol='words_token', outputCol='words_clean')\n",
    "df_clean = remover.transform(df_words_token).select('label', 'words_clean')\n",
    "df_clean.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9fy3-Bgpsbgr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fy3-Bgpsbgr",
    "outputId": "01e03341-30e7-4f22-bfd8-1c21859eed3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             vectors|\n",
      "+-----+--------------------+\n",
      "|  0.0|(13464,[7,11,31,6...|\n",
      "|  0.0|(13464,[0,24,296,...|\n",
      "|  1.0|(13464,[2,13,19,3...|\n",
      "|  0.0|(13464,[0,69,80,1...|\n",
      "|  0.0|(13464,[36,134,31...|\n",
      "|  1.0|(13464,[10,67,139...|\n",
      "|  0.0|(13464,[10,53,103...|\n",
      "|  0.0|(13464,[125,184,4...|\n",
      "|  1.0|(13464,[1,46,118,...|\n",
      "|  1.0|(13464,[0,1,13,27...|\n",
      "|  0.0|(13464,[18,43,120...|\n",
      "|  1.0|(13464,[8,17,37,8...|\n",
      "|  1.0|(13464,[13,30,46,...|\n",
      "|  0.0|(13464,[39,95,217...|\n",
      "|  0.0|(13464,[552,1690,...|\n",
      "|  1.0|(13464,[30,109,11...|\n",
      "|  0.0|(13464,[82,214,37...|\n",
      "|  0.0|(13464,[0,2,49,13...|\n",
      "|  0.0|(13464,[0,74,105,...|\n",
      "|  1.0|(13464,[4,30,33,5...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"words_clean\", outputCol=\"vectors\").fit(df_clean)\n",
    "df_vectorived = cv.transform(df_clean).select('label', 'vectors')\n",
    "df_vectorived.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8ULLnx7iu0Et",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ULLnx7iu0Et",
    "outputId": "54f5bd6b-92cd-48ea-b957-5458880319a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(13464,[7,11,31,6...|\n",
      "|  0.0|(13464,[0,24,296,...|\n",
      "|  1.0|(13464,[2,13,19,3...|\n",
      "|  0.0|(13464,[0,69,80,1...|\n",
      "|  0.0|(13464,[36,134,31...|\n",
      "|  1.0|(13464,[10,67,139...|\n",
      "|  0.0|(13464,[10,53,103...|\n",
      "|  0.0|(13464,[125,184,4...|\n",
      "|  1.0|(13464,[1,46,118,...|\n",
      "|  1.0|(13464,[0,1,13,27...|\n",
      "|  0.0|(13464,[18,43,120...|\n",
      "|  1.0|(13464,[8,17,37,8...|\n",
      "|  1.0|(13464,[13,30,46,...|\n",
      "|  0.0|(13464,[39,95,217...|\n",
      "|  0.0|(13464,[552,1690,...|\n",
      "|  1.0|(13464,[30,109,11...|\n",
      "|  0.0|(13464,[82,214,37...|\n",
      "|  0.0|(13464,[0,2,49,13...|\n",
      "|  0.0|(13464,[0,74,105,...|\n",
      "|  1.0|(13464,[4,30,33,5...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"vectors\", outputCol=\"features\")\n",
    "idfModel = idf.fit(df_vectorived)\n",
    "rescaledData = idfModel.transform(df_vectorived).select(\"label\",\"features\")\n",
    "rescaledData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d4c52",
   "metadata": {
    "id": "ad9d4c52"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9775d494",
   "metadata": {
    "id": "9775d494"
   },
   "source": [
    "## The Model\n",
    "- Create a <b>NaiveBayes</b> classifier with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "57af0d5d",
   "metadata": {
    "id": "57af0d5d"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "54c7384e",
   "metadata": {
    "id": "54c7384e"
   },
   "outputs": [],
   "source": [
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14de63",
   "metadata": {
    "id": "dc14de63"
   },
   "source": [
    "## Pipeline\n",
    "### Create a pipeline model contains all the steps starting from the Tokenizer to the NaiveBays classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8ee0d1ca",
   "metadata": {
    "id": "8ee0d1ca"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7f82bab0",
   "metadata": {
    "id": "7f82bab0"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer,remover, cv, idf,nb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7efbe",
   "metadata": {
    "id": "f5d7efbe"
   },
   "source": [
    "### Split your data to trian and test data with ratios 0.7 and 0.3 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2843d997",
   "metadata": {
    "id": "2843d997"
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "trainDF, testDF = df_ind.randomSplit([0.7,0.3],seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcea576",
   "metadata": {
    "id": "8bcea576"
   },
   "source": [
    "### Fit your Pipeline model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3c5d4681",
   "metadata": {
    "id": "3c5d4681"
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a3eb1",
   "metadata": {
    "id": "228a3eb1"
   },
   "source": [
    "### Perform predictions on tests dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "14f4aab5",
   "metadata": {
    "id": "14f4aab5"
   },
   "outputs": [],
   "source": [
    "prediction = model.transform(testDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2885f",
   "metadata": {
    "id": "bce2885f"
   },
   "source": [
    "### Print the schema of the prediction dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6e3ea341",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e3ea341",
    "outputId": "2ce44410-e987-4064-dfed-cac995079a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- text: string (nullable = true)\n",
      " |-- words_token: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- words_clean: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- vectors: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f27055",
   "metadata": {
    "id": "57f27055"
   },
   "source": [
    "## Model Evaluation\n",
    "- Use <b>MulticlassClassificationEvaluator</b> to calculate the <b>f1_score</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61911086",
   "metadata": {
    "id": "61911086"
   },
   "outputs": [],
   "source": [
    "my_eval_lr.evaluate(predictions_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "be706565",
   "metadata": {
    "id": "be706565"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "wnyCPqHo7S34",
   "metadata": {
    "id": "wnyCPqHo7S34"
   },
   "outputs": [],
   "source": [
    "evaluatorMulti = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "af1f9ba1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af1f9ba1",
    "outputId": "619a93a4-cd50-46ab-d1e9-38e4bbf5b8b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9105008637125755"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = evaluatorMulti.evaluate(prediction, {evaluatorMulti.metricName: \"f1\"})\n",
    "evaluatorMulti.evaluate(prediction)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Spark and Python for Big Data Final Exam-Branches.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
